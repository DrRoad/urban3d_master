#!/usr/bin/env python
# coding: utf-8
from PIL import Image
import cv2
from path import Path
from datasets2 import RSDataset
import torch
import torch.backends.cudnn
from torch.utils.data import DataLoader
import os
import tqdm
import numpy as np
import argparse
import shutil
import glob
import gdal
from scipy import ndimage as ndi
from skimage.morphology import opening, closing, square
from pytorch_toolbelt.inference.tta import TTAWrapper, fliplr_image2mask, d4_image2mask



# need to create a file to store temp pictures
# if not os.path.exists('temp_pic'):
#     os.makedirs('temp_pic')
# path = './temp_pic/'
device = 'cuda:0'
dark = [0,0,0]

## use model to predict
def predict(model):
    result = []
    for images in tqdm.tqdm(test_loader):
        images = images.to(device, dtype=torch.float)
        temp = 0
        for keys in model.keys():
            model[keys].eval()
            net = TTAWrapper(model[keys], fliplr_image2mask)
            outputs = torch.sigmoid(model[keys](images))[0, 0, :, :]
            print(outputs.size())
            temp += outputs
        preds = temp/len(model)
        # preds = torch.from_numpy(preds)
        result.append(preds.detach().cpu().numpy())
    return result


def input_and_output(pic_path, model, generate_data):
    """
    args:
        pic_path : the picture you want to predict
        model    : the model you want to predict
    note:
        step one : generate some pictures from one picture
        step two : predict from the images generated by step one 
    """
    image_size = args.crop_size

    img = cv2.imread(pic_path)
    b = args.padding_size
    image = cv2.copyMakeBorder(img, b, b, b, b, cv2.BORDER_REFLECT)
    # height, width = ndsm.shape
    # ndsm = np.reshape(ndsm,(height,height,1))

    h, w = image.shape[0], image.shape[1]
    row = img.shape[0]//image_size
    col = img.shape[1]//image_size
    padding_img = np.zeros((h, w, 3), dtype=np.uint8)
    padding_img[0:h, 0:w, :] = image[:, :, :]

    padding_img = np.array(padding_img)
#     print ('src:',padding_img.shape)
    mask_whole = np.zeros((row*image_size, col*image_size), dtype=np.float32)
    if generate_data == False:
        result = predict(model)
        map_list = [str(i.name) for i in Path('temp_pic').files()]
    for i in range(row):
        for j in range(col):
            if generate_data:
                crop_img = redundancy_crop(padding_img, i, j, image_size)
                ch,cw,_ = crop_img.shape
                cv2.imwrite(f'temp_pic/{i}_{j}.png',crop_img)
            else:
                temp = result[map_list.index(f'{i}_{j}.png')]
                temp = redundancy_crop2(temp)
                mask_whole[i*image_size:i*image_size+image_size,j*image_size:j*image_size+image_size] = temp
    return mask_whole


def redundancy_crop(img, i, j, targetSize):
    if len(img.shape)>2:
        temp_img = img[i*targetSize:i*targetSize+targetSize+2*args.padding_size, j*targetSize:j*targetSize+targetSize+2*args.padding_size, :]
    else:
        temp_img = img[i*targetSize:i*targetSize+targetSize+2*args.padding_size, j*targetSize:j*targetSize+targetSize+2*args.padding_size]
    return temp_img


def redundancy_crop2(img):
    h = img.shape[0]
    w = img.shape[1]
    temp_img = img[args.padding_size:h-args.padding_size,args.padding_size:w-args.padding_size]
    return temp_img


def get_dataset_loaders( workers):
    batch_size = 1

    test_dataset = RSDataset(
        "./temp_pic"
    )

    test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=workers)
    return test_loader


def get_labels():
    """Load the mapping that associates pascal classes with label colors

    Returns:
        np.ndarray with dimensions (2, 3)
    """
    return np.asarray(
        [
            [0, 0, 0],
            [255, 255, 255]
        ]
    )


def decode_segmap(label_mask, n_classes):
    """Decode segmentation class labels into a color image

    Args:
        label_mask (np.ndarray): an (M,N) array of integer values denoting
          the class label at each spatial location.
        plot (bool, optional): whether to show the resulting color image
          in a figure.

    Returns:
        (np.ndarray, optional): the resulting decoded color image.
    """
    label_colours = get_labels()
    r = label_mask.copy()
    g = label_mask.copy()
    b = label_mask.copy()
    for ll in range(0, n_classes):
        r[label_mask == ll] = label_colours[ll, 0]
        g[label_mask == ll] = label_colours[ll, 1]
        b[label_mask == ll] = label_colours[ll, 2]
    rgb = np.zeros((label_mask.shape[0], label_mask.shape[1], 3))
    rgb[:, :, 0] = r
    rgb[:, :, 1] = g
    rgb[:, :, 2] = b
    return rgb


if __name__ =="__main__":
# def my_predict():
    parse = argparse.ArgumentParser()
    parse.add_argument("--n_class", type=int, default=2, help="the number of classes")
    parse.add_argument("--model_name", type=str, default='UNet', help="UNet,PSPNet,FPN")

    parse.add_argument("--n_workers", type=int, default=4, help="the number of workers")
    parse.add_argument("--crop_size", type=int, default=512, help="the number of workers")
    parse.add_argument("--padding_size", type=int, default=32, help="the number of workers")
    parse.add_argument("--component_size", type=int, default=81, help="the size of component")

    args = parse.parse_args()
    # model_groups = ["UNet","PSPNet","FPN"]
    model_groups = ["YpUNet_val_0.8450053535676032_epoch69.pth"]
    # model_groups = ["FPN_val_0.85409586260551_epoch120.pth"]

# predict on more model
    models={}
    for index, item in enumerate(model_groups):
        models[item] = model = torch.load(f'./results_UNet/{item}', map_location='cuda:0')["model_state"]

    # model = torch.load(f'./results_{args.model_name}/{args.model_name}_weights_best.pth')["model_state"]

    imgList = glob.glob("./valid/*RGB.tif")
    num = len(imgList)

    save_path = f'./predict_YpUnet'
    if not os.path.exists(save_path):
        os.makedirs(save_path)

    for i in tqdm.tqdm(range(num)):
        if not os.path.exists('temp_pic'):
            os.makedirs('temp_pic')
        ### predict on one picture


        input_and_output(imgList[i], models, generate_data=True)
        name = os.path.split(imgList[i])[-1].split(".")[0]
        test_loader = get_dataset_loaders(args.n_workers)
        mask_result = input_and_output(imgList[i], models, generate_data=False)
        # 递归删除文件夹
        try:
            shutil.rmtree('temp_pic')
            shutil.rmtree('temp_ndsm')
        except:
            pass
        # dsm_ds = gdal.Open(imgList[i].replace("RGB", "DSM"), gdal.GA_ReadOnly)
        # band_dsm = dsm_ds.GetRasterBand(1)
        # nodata = band_dsm.GetNoDataValue()
        # dsm = band_dsm.ReadAsArray()
        #
        # mask_result[dsm == nodata] = 0
        threshold = 0.5
        mask_result[mask_result > threshold] = 1
        mask_result[mask_result <= threshold] = 0

        mask_result = opening(mask_result, square(6))
        labels = ndi.label(mask_result, output=np.uint32)[0]
        unique, counts = np.unique(labels, return_counts=True)
        for (k, v) in dict(zip(unique, counts)).items():
            if v < args.component_size:
                print("remove small objects successfully")
                mask_result[labels == k] = 0


        decoded = decode_segmap(mask_result, args.n_class)

        # print(mask_result.shape)
        cv2.imwrite(f'{save_path}/{name}.png', decoded)